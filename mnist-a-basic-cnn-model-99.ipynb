{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading Datasets and Importing Libraries ","metadata":{}},{"cell_type":"code","source":"# Importing Tensorflow and the required visualization libraries\nimport tensorflow as tf\ntf.config.experimental_run_functions_eagerly(True)\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\n#Loading the Dataset\ntrain = pd.read_csv('/kaggle/input/digit-recognizer/train.csv')\ntest = pd.read_csv('/kaggle/input/digit-recognizer/test.csv')\n","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Seperating the independent feature as y\ny = train['label']\ntrain = train.drop('label', axis =1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualizing Data","metadata":{}},{"cell_type":"code","source":"#Visualizing the Distribution of digits in labels\nsns.countplot(y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Visualing an example \nimg = train.iloc[10].to_numpy()\nimg = img.reshape((28,28))\nplt.imshow(img,cmap='gray')\nplt.title(y.iloc[10])\nplt.axis(\"off\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing Data","metadata":{}},{"cell_type":"code","source":"#Preprocessing the Data\ntrain=train/225.0\ntest = test/225.0\ntrain = np.array(train)\ntest= np.array(test)\ntrain = train.reshape(train.shape[0], 28, 28,1)\ntest = test.reshape(test.shape[0], 28, 28,1)\n\n#Splitting the data into training and validation \nfrom sklearn.model_selection import train_test_split\nX_train, X_val, Y_train, Y_val = train_test_split(train, y, test_size=0.2)\n\n#Converting the train and validation labels to one-hot encodings\nY_train = tf.keras.utils.to_categorical(Y_train, num_classes=10)\nY_val = tf.keras.utils.to_categorical(Y_val, num_classes=10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Building, Compiling and Training model","metadata":{}},{"cell_type":"code","source":"#Preparing a CNN model architecture\nmodel = tf.keras.models.Sequential([\n            tf.keras.layers.Conv2D(32, (5,5), activation='relu', kernel_initializer='he_uniform',input_shape=(28, 28, 1)),\n            tf.keras.layers.MaxPooling2D(2, 2),\n            tf.keras.layers.Dropout(0.2),\n            tf.keras.layers.Conv2D(64, (5,5), activation='relu'),\n            tf.keras.layers.MaxPooling2D(2, 2),\n            \n            \n            tf.keras.layers.Dropout(0.25),\n            tf.keras.layers.Flatten(),\n            tf.keras.layers.Dense(128, activation='relu'),\n            tf.keras.layers.BatchNormalization(),\n            tf.keras.layers.Dense(10, activation='softmax')\n    ])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Getting the model framework/summary \nfrom keras.utils import plot_model\nplot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)\nfrom IPython.display import Image\nImage(\"model.png\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Compiling the model\nmodel.compile(optimizer= tf.keras.optimizers.SGD(lr=0.1, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Data augmentation to prevent overfitting\ndatagen = tf.keras.preprocessing.image.ImageDataGenerator(\n        rotation_range=30, \n        zoom_range = 0.2, \n        width_shift_range=0.1,  \n        height_shift_range=0.1,)  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Training the model\nhistory = model.fit_generator(datagen.flow(X_train, Y_train,batch_size=64),validation_data=(X_val, Y_val),epochs=15,steps_per_epoch=X_train.shape[0] // 64)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluating Results","metadata":{}},{"cell_type":"code","source":"#Comparing losses and accuraries \nplt.plot(history.history['loss'], color='r')\nplt.plot(history.history['val_loss'], color='b')\nplt.show()\nplt.plot(history.history['accuracy'], color='r')\nplt.plot(history.history['val_accuracy'], color='b')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Plotting Confusion Matrix\ny_pred1 = model.predict(X_val)\ny_pred1 = np.argmax(y_pred1, axis=1)\ny_true = np.argmax(Y_val, axis=1)\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_true, y_pred1)\nprint(cm)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Saving the Predictions","metadata":{}},{"cell_type":"code","source":"#Predicting and Saving it as a CSV file\ny_pred = model.predict(test)\ny_pred = np.argmax(y_pred, axis=1)\ny_pred = pd.Series(y_pred, name='Label')\nsub = pd.concat([pd.Series(range(1, 28001), name=\"ImageId\"), y_pred], axis=1)\nsub.to_csv('/kaggle/working/RESULT.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Please do upvote the kernel if you like my work and share your views in the comments.\n\n# Good Day! :)","metadata":{}}]}